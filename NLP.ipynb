{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2599bd2-11b0-4290-be75-ee01e6db3520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q --upgrade rouge-score\n",
    "%pip install -q --upgrade keras-nlp\n",
    "%pip install -q --upgrade keras  # Upgrade to Keras 3.\n",
    "\n",
    "#from ann_visualizer.visualize import ann_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "371208c2-1e33-42f4-a28b-fd1612606d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_nlp\n",
    "import pathlib\n",
    "import random\n",
    "import os\n",
    "# Loss and metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "os.chdir(\"/media/damian/PDB_DB/TRANSLATION/MODEL\")\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras import ops\n",
    "\n",
    "import tensorflow.data as tf_data\n",
    "from tensorflow_text.tools.wordpiece_vocab import (\n",
    "    bert_vocab_from_dataset as bert_vocab,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f3fdd15-d5bf-4e07-9daf-81c0ca38c519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 300\n",
    "MAX_SEQUENCE_LENGTH = 300\n",
    "AA_VOCAB_SIZE = 100\n",
    "PF_VOCAB_SIZE = 100\n",
    "EMBED_DIM = 128\n",
    "INTERMEDIATE_DIM = 2048\n",
    "NUM_HEADS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f99ad287-2cdc-45a8-a042-7dfec8fba44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = \"GLOBAL_150_300_subset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f37c5038-e6e9-4d98-aeef-4dd5e02b7a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordmaker_kmer(seq):\n",
    "    k = 1 # length of the k-mer\n",
    "    output = [seq[i:i+k] for i in range(len(seq) - k + 1)]\n",
    "    return \" \".join(output)\n",
    "\n",
    "def wordmaker_non_overlapping(seq, word_length=1):\n",
    "    output = [seq[i:i+word_length] for i in range(0, len(seq), word_length)]\n",
    "    return \" \".join(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2fe8f2b-99b8-430f-8f5c-a34d21906bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(text_file) as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "text_pairs = []\n",
    "for line in lines:\n",
    "    AA, PF = line.split(\",\")\n",
    "    AA = wordmaker_non_overlapping(AA.lower())\n",
    "    PF = wordmaker_non_overlapping(PF)\n",
    "    text_pairs.append((AA, PF))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "095cbe3e-e738-4ecc-a139-77bd10a74e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('m r v l g v d p g l t r c g l g v v d g g l g i r a h l v e v g v v r t p a t a e v a e r l c a v s d g i d a w l d r t r p e a v a v e k v f s q a n m r t v m g t a q a g a v a i v l a a r r g l p v g l y t p s e v k a a v t g s g r a d k a q v s f m i t r l l g l t e a p r p a d a a d a l a l a l c h l w r g p a l a r f r s a a p g g p t r', 'u o j g b e e j j m o l g d d c h j n r t B I x A p o o o p l m k l p q z B D A z x x t o o q o k n p n n p r p q u v t t q r p l i k m r x E E K H G D D y u u q m q p k m q o n q t r q u y x y t u r p q p r s s p l m o m m p s t s y w y w w s n n p n k n p p p t v E A t s v t r o f h g a a d c c f i j m p q r w x x y C E F I L N S V U W Z Z')\n",
      "('m l y p t p i a k l i d s f s k l p g i g a k t a t r l a f y t i s m s d e d v n d f a k n l l a a k r e l t y c s v c g r l t d d d p c i i c t d e t r d r t k i l v v e d s k d v s a m e k i q e y r g l y h v l q g l i s p m n g v g p d d i n l k s l i t r l m d s e v d e v i i a t n a t a d g e a t s m y i s r v l k p a g i k v t r l a r g l a v g s d i e y a d e v t l l r a i e n r t e l', 'Y X V V V T P S R L N R P N S U U W X U V U V U P Q S P K Q S O R U U V U V T P R R N K N M J K K J L M L J G A w y s m s w D E I G C z A E B x D G J L E C A A u h e a o w A B G C A G H E H L L L L G G x r j a o t B D D F K N Q Q P L K G J I D y x B w q y A v x F H E F z C x n k h o u C E G H F A A D y u A C x y F E C G L I J D C w w u z F F G N S V X V V T W W T T T R M N P K J P Q O R W Y Z')\n",
      "('m l t k k q l q l l e f i h k r l q k d g v p p s f d e m k t a l d l r s k s g i h r l i t a l e e r g f i r r l a h r a r a i e v i r l p d s l g g g g a l g a a s d g f q p k v i a g g r g d s a d g g a a a e l k p v a d t g a t e l t i m g r i a a g v p i e a i n q a a a h v a v p n a m l s s s g q h y a l e v r g d s m i d a g i n d g d v v v i r e t d a a d n g d i v v a l v e g h e a t l k r f e r k g r m i e l h a a n p a y p t r s y t e d q v k v q g r l v g l i r t y', 'V S S R P L J J E y G H z H O O N S U U T Q J M Q R V T P U V T T W W X X W W V S U U Q O T T P S W V U Q N R R T V W U T O O J M M S T R T V U S V X X X Y Y Z Z Z Z Z Z Z Z Z Z Y Y X X Y X Y Z Z Z Z Z Z Z Z Z Z Y Y Y X X W W W U U T R S P Q Q P K P P S S T S V V T V W W V U T S T R T T U R R T V V U S O M J I N M R T T R P U V S T Q T T T Q M E E A J N P Q Q M P Q O I y a b y K M S T S O I B r y F F N Q T V U S O M H M O R U W W U U R P Q Q S S U S N O I J E z w I K M Q T W X')\n",
      "('m t e k i g l f t g t f d p l t n g h l d v i k r a s q h f d q l y v g i f k n d q k n p l f p t d k r v e m l e e a l t s l s v t h k v k v i k h e r d l t v n i a k k l g v t a l v r s l r n s q d l e y e k n m f y f n m e m t g i e t i f f l a k p e l e p l n s t r m r e l h a f g q d v s a w v p e n v s r e l r k l d e k k', 'Z X P A o e a l t A x v u r p m o s r s s r p t v s q D E w A s f j l q q y F M S T P S H F D E C D y s u v t s v w v s z E D D z x I y s w v y y F I L M I E A D B v B H G F u u s m n w w C G N P Q I G M M F H K I E I I D D K K G F C A x x y z B z H K M y A H C C y E D y B F E D K N N L M E z H A p x z z s u A B B E J M N S U W')\n",
      "('m g a g a l g v v a m v a a a v v v a m a g a n s e g d a l s a l r r s l r d p g g v l q s w d p t l v n p c t w f h v t c d r d n r v t r l d l g n l n l s g h l v p e l g k l d h l q y l e l y k n n i q g t i p s e l g n l k n l i s l d l y k n n i s g t i p p t l g k l t s l v f l r l n g n r l t g p i p r e l a g i s s l k v v d v s s n d l c g t i p t s g p f e h i p l s n f e k n p r l e g p e l q g l a v y d t n c', 'Z Z Y X V S P M K I F J F H H G G F D D B A A x w t t u r p r r n o r p m o n o n o m n q r r u v y x y w s s t q n k m o r t w x v t p n j h g e e h i j i k m l i n o q m n r p q p l j g c b b c g g j h j l j f j k m h i n l m m h h d a a a d h g j g j k i e g h i e f j h k k g i f b c b h k i l i l l j g f h h e h j i l l i l j g h h m n l o l o o o m k o n m l l p q o r s s n n r r p t s p r s s w v w x v t r o p o r r')\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    print(random.choice(text_pairs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8245b3b3-9450-4eb3-8661-0aa1db8af861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162998 total pairs\n",
      "114100 training pairs\n",
      "24449 validation pairs\n",
      "24449 test pairs\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(text_pairs)\n",
    "num_val_samples = int(0.15 * len(text_pairs))\n",
    "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
    "train_pairs = text_pairs[:num_train_samples]\n",
    "val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n",
    "test_pairs = text_pairs[num_train_samples + num_val_samples :]\n",
    "\n",
    "print(f\"{len(text_pairs)} total pairs\")\n",
    "print(f\"{len(train_pairs)} training pairs\")\n",
    "print(f\"{len(val_pairs)} validation pairs\")\n",
    "print(f\"{len(test_pairs)} test pairs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3166039-0f72-4f27-89f4-25b998533aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_word_piece(text_samples, vocab_size, reserved_tokens):\n",
    "    word_piece_ds = tf_data.Dataset.from_tensor_slices(text_samples)\n",
    "    vocab = keras_nlp.tokenizers.compute_word_piece_vocabulary(\n",
    "        word_piece_ds.batch(1000).prefetch(2),\n",
    "        vocabulary_size=vocab_size,\n",
    "        reserved_tokens=reserved_tokens,\n",
    "    )\n",
    "    return vocab\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "564cfecc-58fe-435f-b8f1-0674dc553bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-19 15:27:09.837864: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-19 15:27:13.578975: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "reserved_tokens = [\"[PAD]\", \"[UNK]\", \"[START]\", \"[END]\"]\n",
    "\n",
    "\n",
    "AA_samples = [text_pair[0] for text_pair in train_pairs]\n",
    "AA_vocab = train_word_piece(AA_samples, AA_VOCAB_SIZE, reserved_tokens)\n",
    "\n",
    "PF_samples = [text_pair[1] for text_pair in train_pairs]\n",
    "PF_vocab = train_word_piece(PF_samples, PF_VOCAB_SIZE, reserved_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "1dabe655-0c5d-4339-97bf-cab43a739aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AA Tokens:  ['h', 'i', 'k', 'l', 'm', 'n', 'p', 'q', 'r', 's']\n",
      "Proflex Tokens:  ['G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P']\n"
     ]
    }
   ],
   "source": [
    "print(\"AA Tokens: \", AA_vocab[10:20])\n",
    "print(\"Proflex Tokens: \", PF_vocab[10:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c863adbd-e582-4e2c-aad8-fdba30a34187",
   "metadata": {},
   "outputs": [],
   "source": [
    "AA_tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n",
    "    vocabulary=AA_vocab, lowercase=False\n",
    ")\n",
    "PF_tokenizer = keras_nlp.tokenizers.WordPieceTokenizer(\n",
    "    vocabulary=PF_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5906551b-1f8d-4689-bf02-e659adff3e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AA seq:  m a s r g v n k v i l v g n l g q d p e v r y m p s g g a v a n l t l a t s e s w r d k q t g e m k e q t e w h r v v m f g k l a e v a g e y l r k g s q v y i e g q l r t r k w t d q s g q e r y t t e i n v p q i g g v m q m l g g r q g g g a p a g g q q q g g w g q p q q p q q p q g g n q f s g g a q s r p q q s a p a p s n e p p m d f d d d i p f\n",
      "Tokens:  tf.Tensor(\n",
      "[14  4 19 18  9 21 15 12 21 11 13 21  9 15 13  9 17  6 16  7 21 18 23 14\n",
      " 16 19  9  9  4 21  4 15 13 20 13  4 20 19  7 19 22 18  6 12 17 20  9  7\n",
      " 14 12  7 17 20  7 22 10 18 21 21 14  8  9 12 13  4  7 21  4  9  7 23 13\n",
      " 18 12  9 19 17 21 23 11  7  9 17 13 18 20 18 12 22 20  6 17 19  9 17  7\n",
      " 18 23 20 20  7 11 15 21 16 17 11  9  9 21 14 17 14 13  9  9 18 17  9  9\n",
      "  9  4 16  4  9  9 17 17 17  9  9 22  9 17 16 17 17 16 17 17 16 17  9  9\n",
      " 15 17  8 19  9  9  4 17 19 18 16 17 17 19  4 16  4 16 19 15  7 16 16 14\n",
      "  6  8  6  6  6 11 16  8], shape=(176,), dtype=int32)\n",
      "Recovered seq after detokenizing:  tf.Tensor(b'm a s r g v n k v i l v g n l g q d p e v r y m p s g g a v a n l t l a t s e s w r d k q t g e m k e q t e w h r v v m f g k l a e v a g e y l r k g s q v y i e g q l r t r k w t d q s g q e r y t t e i n v p q i g g v m q m l g g r q g g g a p a g g q q q g g w g q p q q p q q p q g g n q f s g g a q s r p q q s a p a p s n e p p m d f d d d i p f', shape=(), dtype=string)\n",
      "\n",
      "PF seq:  S P N K H E z w s u s w v w t v x y u v w z B D H G E A x t q m k k m s v z C F H J J L M M M K J F D z v q k d a a g k r v v r r w w t x A A y A A A z z v v p r o q p q s w A C F G K K J G E z v p k e d j k r t x x s s r w y C E H I J L L N P P Q R S U W X Y Y Y Y X Y Y Z Z Z Z Z Z Z Z Z Y Y Y X X W V U T S R Q P N L L J J K J J I I J I M N O O Q T\n",
      "Tokens:  tf.Tensor(\n",
      "[22 19 17 14 11  8 55 52 48 50 48 52 51 52 49 51 53 54 50 51 52 55  5  7\n",
      " 11 10  8  4 53 49 46 42 40 40 42 48 51 55  6  9 11 13 13 15 16 16 16 14\n",
      " 13  9  7 55 51 46 40 33 30 30 36 40 47 51 51 47 47 52 52 49 53  4  4 54\n",
      "  4  4  4 55 55 51 51 45 47 44 46 45 46 48 52  4  6  9 10 14 14 13 10  8\n",
      " 55 51 45 40 34 33 39 40 47 49 53 53 48 48 47 52 54  6  8 11 12 13 15 15\n",
      " 17 19 19 20 21 22 24 26 27 28 28 28 28 27 28 28 29 29 29 29 29 29 29 29\n",
      " 29 28 28 28 27 27 26 25 24 23 22 21 20 19 17 15 15 13 13 14 13 13 12 12\n",
      " 13 12 16 17 18 18 20 23], shape=(176,), dtype=int32)\n",
      "Recovered seq after detokenizing:  tf.Tensor(b'S P N K H E z w s u s w v w t v x y u v w z B D H G E A x t q m k k m s v z C F H J J L M M M K J F D z v q k d a a g k r v v r r w w t x A A y A A A z z v v p r o q p q s w A C F G K K J G E z v p k e d j k r t x x s s r w y C E H I J L L N P P Q R S U W X Y Y Y Y X Y Y Z Z Z Z Z Z Z Z Z Y Y Y X X W V U T S R Q P N L L J J K J J I I J I M N O O Q T', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "AA_input_ex = text_pairs[0][0]\n",
    "AA_tokens_ex = AA_tokenizer.tokenize(AA_input_ex)\n",
    "print(\"AA seq: \", AA_input_ex)\n",
    "print(\"Tokens: \", AA_tokens_ex)\n",
    "print(\n",
    "    \"Recovered seq after detokenizing: \",\n",
    "    AA_tokenizer.detokenize(AA_tokens_ex),\n",
    ")\n",
    "\n",
    "print()\n",
    "\n",
    "PF_input_ex = text_pairs[0][1]\n",
    "PF_tokens_ex = PF_tokenizer.tokenize(PF_input_ex)\n",
    "print(\"PF seq: \", PF_input_ex)\n",
    "print(\"Tokens: \", PF_tokens_ex)\n",
    "print(\n",
    "    \"Recovered seq after detokenizing: \",\n",
    "    PF_tokenizer.detokenize(PF_tokens_ex),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e7bb6cb-5662-4837-8bb8-2863e9716682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_batch(AA, PF):\n",
    "    batch_size = ops.shape(PF)[0]\n",
    "\n",
    "    AA = AA_tokenizer(AA)\n",
    "    PF = PF_tokenizer(PF)\n",
    "\n",
    "    # Pad `eng` to `MAX_SEQUENCE_LENGTH`.\n",
    "    AA_start_end_packer = keras_nlp.layers.StartEndPacker(\n",
    "        sequence_length=MAX_SEQUENCE_LENGTH,\n",
    "        pad_value=AA_tokenizer.token_to_id(\"[PAD]\"),\n",
    "    )\n",
    "    AA = AA_start_end_packer(AA)\n",
    "\n",
    "    # Add special tokens (`\"[START]\"` and `\"[END]\"`) to PF and pad it as well.\n",
    "    PF_start_end_packer = keras_nlp.layers.StartEndPacker(\n",
    "        sequence_length=MAX_SEQUENCE_LENGTH + 1,\n",
    "        start_value=PF_tokenizer.token_to_id(\"[START]\"),\n",
    "        end_value=PF_tokenizer.token_to_id(\"[END]\"),\n",
    "        pad_value=PF_tokenizer.token_to_id(\"[PAD]\"),\n",
    "    )\n",
    "    PF = PF_start_end_packer(PF)\n",
    "\n",
    "    return (\n",
    "        {\n",
    "            \"encoder_inputs\": AA,\n",
    "            \"decoder_inputs\": PF[:, :-1],\n",
    "        },\n",
    "        PF[:, 1:],\n",
    "    )\n",
    "\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    AA_texts, PF_texts = zip(*pairs)\n",
    "    AA_texts = list(AA_texts)\n",
    "    PF_texts = list(PF_texts)\n",
    "    dataset = tf_data.Dataset.from_tensor_slices((AA_texts, PF_texts))\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.map(preprocess_batch, num_parallel_calls=tf_data.AUTOTUNE)\n",
    "    return dataset.shuffle(1024).prefetch(64).cache()\n",
    "\n",
    "\n",
    "train_ds = make_dataset(train_pairs)\n",
    "val_ds = make_dataset(val_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5f41595-454e-4e4a-bbc4-f6dbdfffbd03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs[\"encoder_inputs\"].shape: (256, 300)\n",
      "inputs[\"decoder_inputs\"].shape: (256, 300)\n",
      "targets.shape: (256, 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-19 15:27:45.261344: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-08-19 15:27:45.262205: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds.take(1):\n",
    "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
    "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
    "    print(f\"targets.shape: {targets.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7145af96-c863-4105-8e47-68b401d0011c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"transformer\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ token_and_position… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">51,200</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionE…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_encode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">593,024</span> │ token_and_positi… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ functional_7        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">723,428</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │ transformer_enco… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ token_and_position… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m51,200\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mTokenAndPositionE…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_encode… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │    \u001b[38;5;34m593,024\u001b[0m │ token_and_positi… │\n",
       "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ functional_7        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m100\u001b[0m)  │    \u001b[38;5;34m723,428\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │ transformer_enco… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,367,652</span> (5.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,367,652\u001b[0m (5.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,367,652</span> (5.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,367,652\u001b[0m (5.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Encoder\n",
    "encoder_inputs = keras.Input(shape=(MAX_SEQUENCE_LENGTH,), name=\"encoder_inputs\")\n",
    "\n",
    "x = keras_nlp.layers.TokenAndPositionEmbedding(\n",
    "    vocabulary_size=AA_VOCAB_SIZE,\n",
    "    sequence_length=MAX_SEQUENCE_LENGTH,\n",
    "    embedding_dim=EMBED_DIM,\n",
    ")(encoder_inputs)\n",
    "\n",
    "encoder_outputs = keras_nlp.layers.TransformerEncoder(\n",
    "    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n",
    ")(inputs=x)\n",
    "\n",
    "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = keras.Input(shape=(MAX_SEQUENCE_LENGTH,), name=\"decoder_inputs\")\n",
    "encoded_seq_inputs = keras.Input(shape=(MAX_SEQUENCE_LENGTH, EMBED_DIM), name=\"decoder_state_inputs\")\n",
    "\n",
    "x = keras_nlp.layers.TokenAndPositionEmbedding(\n",
    "    vocabulary_size=PF_VOCAB_SIZE,\n",
    "    sequence_length=MAX_SEQUENCE_LENGTH,\n",
    "    embedding_dim=EMBED_DIM,\n",
    ")(decoder_inputs)\n",
    "\n",
    "x = keras_nlp.layers.TransformerDecoder(\n",
    "    intermediate_dim=INTERMEDIATE_DIM, num_heads=NUM_HEADS\n",
    ")(decoder_sequence=x, encoder_sequence=encoded_seq_inputs)\n",
    "x = keras.layers.Dropout(0.1)(x)\n",
    "decoder_outputs = keras.layers.Dense(PF_VOCAB_SIZE, activation=\"softmax\")(x)\n",
    "\n",
    "decoder = keras.Model(\n",
    "    [\n",
    "        decoder_inputs,\n",
    "        encoded_seq_inputs,\n",
    "    ],\n",
    "    decoder_outputs,\n",
    ")\n",
    "\n",
    "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
    "\n",
    "transformer = keras.Model(\n",
    "    [encoder_inputs, decoder_inputs],\n",
    "    decoder_outputs,\n",
    "    name=\"transformer\",\n",
    ")\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping_callback = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=8,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Custom loss function\n",
    "def custom_loss(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_object = keras.losses.SparseCategoricalCrossentropy(from_logits=False, reduction='none')\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "# Learning rate schedule\n",
    "learning_rate = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.001,  # Lower initial learning rate\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True\n",
    ")\n",
    "\n",
    "# Optimizer\n",
    "optimiser = keras.optimizers.Adam(learning_rate)\n",
    "\n",
    "transformer.summary()\n",
    "# Compile the model\n",
    "transformer.compile(optimizer=optimiser, loss=custom_loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "b954eb00-71e9-456e-8d50-7122631ce276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"transformer\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"transformer\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ token_and_position… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">51,200</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionE…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_encode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">593,024</span> │ token_and_positi… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ functional_33       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">723,428</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │ transformer_enco… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ token_and_position… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │     \u001b[38;5;34m51,200\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mTokenAndPositionE…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_encode… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │    \u001b[38;5;34m593,024\u001b[0m │ token_and_positi… │\n",
       "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ functional_33       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m100\u001b[0m)  │    \u001b[38;5;34m723,428\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │ transformer_enco… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,367,652</span> (5.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,367,652\u001b[0m (5.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,367,652</span> (5.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,367,652\u001b[0m (5.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3973s\u001b[0m 9s/step - accuracy: 0.0539 - loss: 3.4806 - val_accuracy: 0.1371 - val_loss: 3.1701\n",
      "Epoch 2/300\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3956s\u001b[0m 9s/step - accuracy: 0.5997 - loss: 0.7495 - val_accuracy: 0.7413 - val_loss: 0.0041\n",
      "Epoch 3/300\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3952s\u001b[0m 9s/step - accuracy: 0.7432 - loss: 0.0041 - val_accuracy: 0.7413 - val_loss: 0.0029\n",
      "Epoch 4/300\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3970s\u001b[0m 9s/step - accuracy: 0.7432 - loss: 0.0030 - val_accuracy: 0.7413 - val_loss: 0.0025\n",
      "Epoch 5/300\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3974s\u001b[0m 9s/step - accuracy: 0.7432 - loss: 0.0026 - val_accuracy: 0.7413 - val_loss: 0.0023\n",
      "Epoch 6/300\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3973s\u001b[0m 9s/step - accuracy: 0.7432 - loss: 0.0024 - val_accuracy: 0.7413 - val_loss: 0.0022\n",
      "Epoch 7/300\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3962s\u001b[0m 9s/step - accuracy: 0.7433 - loss: 0.0023 - val_accuracy: 0.7413 - val_loss: 0.0022\n",
      "Epoch 8/300\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3959s\u001b[0m 9s/step - accuracy: 0.6497 - loss: 0.5167 - val_accuracy: 0.0489 - val_loss: 3.4390\n",
      "Epoch 9/300\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3964s\u001b[0m 9s/step - accuracy: 0.0497 - loss: 3.4124 - val_accuracy: 0.0613 - val_loss: 3.2373\n",
      "Epoch 10/300\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3966s\u001b[0m 9s/step - accuracy: 0.0817 - loss: 3.0412 - val_accuracy: 0.0923 - val_loss: 5.3576\n",
      "Epoch 11/300\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3960s\u001b[0m 9s/step - accuracy: 0.4335 - loss: 1.6066 - val_accuracy: 0.7086 - val_loss: 0.1414\n",
      "Epoch 12/300\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3960s\u001b[0m 9s/step - accuracy: 0.7110 - loss: 0.1362 - val_accuracy: 0.7105 - val_loss: 0.1224\n",
      "Epoch 13/300\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3992s\u001b[0m 9s/step - accuracy: 0.5823 - loss: 0.7805 - val_accuracy: 0.7070 - val_loss: 0.3646\n",
      "Epoch 14/300\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4030s\u001b[0m 9s/step - accuracy: 0.7134 - loss: 0.2357 - val_accuracy: 0.7168 - val_loss: 0.1015\n",
      "Epoch 15/300\n",
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4030s\u001b[0m 9s/step - accuracy: 0.7187 - loss: 0.1007 - val_accuracy: 0.7178 - val_loss: 0.0944\n"
     ]
    }
   ],
   "source": [
    "transformer.summary()\n",
    "# Compile the model\n",
    "transformer.compile(optimizer=optimiser, loss=custom_loss, metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = transformer.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[early_stopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67341e10-98f1-4c66-aca7-1c3c594e3ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "custom_objects = {\n",
    "    'custom_loss': custom_loss,\n",
    "    # Add other custom objects here if needed\n",
    "}\n",
    "\n",
    "model_path = 'model2.keras'\n",
    "transformer = load_model(model_path, custom_objects=custom_objects)\n",
    "#transformer.compile(optimizer=optimiser, loss=custom_loss, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#%pip install graphviz\n",
    "#import graphviz\n",
    "#plot_model(transformer, to_file='transformer_model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "71994170-0f96-4bcf-a96a-cb0bb45c4a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m s t l e q k l t e m l t a p v e a l g f e l v g i e f i r g r t s t l r i y i d s e d g i n v d d c a d v s h q v s a v m d v e d p i t v a y n l e v s s p g l d r p m f t a e h y q r f t g e e v a l v l r m a v q n r r k w q g i i k a v d g e m i t v t v e g k d e v f a l s n i q k a n l v p h f\n",
      "P Q J D N I J Q D K J Q A M R D A J F E D J R F H D E H O F O Q P Q J O H T H C P D C F H L R C C B A C R P G N R P A R K C R D C M H Q R A T L J D R P P M F J C O M K E Q A D G T N O E Q F D D R A J R J O K A R N L O O I S N F H H I A R C F D K H Q R Q R D F I C D R E A J P L H N I A L J R M G E\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "\n",
    "def decode_sequences(input_sentences):\n",
    "    batch_size = 1\n",
    "    \n",
    "    # Tokenize the encoder input \n",
    "    encoder_input_tokens = AA_tokenizer(input_sentences)\n",
    "    if isinstance(encoder_input_tokens, tf.RaggedTensor):\n",
    "        encoder_input_tokens = encoder_input_tokens.to_tensor()\n",
    "    encoder_input_tokens = tf.convert_to_tensor(encoder_input_tokens, dtype=tf.int32)\n",
    "    \n",
    "    # Limit input sequence\n",
    "    input_length = tf.shape(encoder_input_tokens)[1]\n",
    "    if input_length > MAX_SEQUENCE_LENGTH:\n",
    "        raise ValueError(\"Input sequence length exceeds MAX_SEQUENCE_LENGTH.\")\n",
    "    \n",
    "    # Pad the input sequence \n",
    "    if input_length < MAX_SEQUENCE_LENGTH:\n",
    "        pads = tf.fill([batch_size, MAX_SEQUENCE_LENGTH - input_length], 0)\n",
    "        encoder_input_tokens = tf.concat([encoder_input_tokens, pads], axis=1)\n",
    "    \n",
    "    def next(prompt, cache, index):\n",
    "        logits = transformer([encoder_input_tokens, prompt])[:, index - 1, :]\n",
    "        hidden_states = None\n",
    "        return logits, hidden_states, cache\n",
    "\n",
    "    # Build a prompt of length MAX_SEQUENCE_LENGTH with a start token and padding tokens.\n",
    "    start = tf.fill([batch_size, 1], PF_tokenizer.token_to_id(\"[START]\"))\n",
    "    pad = tf.fill([batch_size, MAX_SEQUENCE_LENGTH - 1], PF_tokenizer.token_to_id(\"[PAD]\"))\n",
    "    prompt = tf.concat([start, pad], axis=1)\n",
    "\n",
    "    # Greedy sampling\n",
    "    generated_tokens = keras_nlp.samplers.GreedySampler()(\n",
    "        next,\n",
    "        prompt,\n",
    "        stop_token_ids=[PF_tokenizer.token_to_id(\"[END]\")],\n",
    "        index=1,  # Start sampling after start token.\n",
    "    )\n",
    "    \n",
    "    # Truncate or pad the generated tokens to ensure they match the input length\n",
    "    if tf.shape(generated_tokens)[1] > input_length:\n",
    "        generated_tokens = generated_tokens[:, :input_length]\n",
    "    elif tf.shape(generated_tokens)[1] < input_length:\n",
    "        pads = tf.fill([batch_size, input_length - tf.shape(generated_tokens)[1]], PF_tokenizer.token_to_id(\"[PAD]\"))\n",
    "        generated_tokens = tf.concat([generated_tokens, pads], axis=1)\n",
    "    \n",
    "    # Detokenize the generated tokens to obtain the output sentences.\n",
    "    generated_sentences = PF_tokenizer.detokenize(generated_tokens)\n",
    "    \n",
    "    return generated_sentences\n",
    "\n",
    "# Apply decoder\n",
    "test_AA = [pair[0] for pair in test_pairs if len(pair[0]) <= MAX_SEQUENCE_LENGTH]\n",
    "\n",
    "for i in range(1):\n",
    "    seq = random.choice(test_AA)\n",
    "    translated = decode_sequences([seq])\n",
    "    translated = translated.numpy()[0].decode(\"utf-8\")\n",
    "    translated = (\n",
    "        translated.replace(\"[PAD]\", \"\")\n",
    "        .replace(\"[START]\", \"\")\n",
    "        .replace(\"[END]\", \"\")\n",
    "        .strip()\n",
    "    )\n",
    "    print(f'{seq}')\n",
    "    print(f'{translated}')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "5e9f1b52-4b17-4a2a-b222-0872c5fb3948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "\n",
    "transformer.save('model2.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd206e26-8051-47c0-8997-9c63b24ba7ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
